"""
Report Generator Agent Server
==============================
DeepAgents í”„ë ˆì„ì›Œí¬ ê¸°ë°˜: ì™¸ë¶€ ì½”ë“œë¥¼ í‘œì¤€ ì½”ë“œë¡œ ë³€í™˜í•˜ê³  ì§‘ê³„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±

Usage:
    python -m agents.report_generator.server
"""

import sys
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from langchain.chat_models import init_chat_model
from langchain_core.runnables import RunnableLambda
from langserve import add_routes
from deepagents import create_deep_agent
from deepagents.backends import FilesystemBackend
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.types import Command

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from agents.report_generator.config import (
    get_model_config,
    get_system_prompt,
    get_agents_md_path,
    get_skills_paths,
    get_mcp_server_config
)
from agents.report_generator.schemas import ReportInput, ReportOutput
from agents.report_generator.tools.aggregate import aggregate_by_standard_code
from agents.report_generator.tools.markdown import generate_markdown_report
from agents.report_generator.tools.finance import get_exchange_rate
from agents.report_generator.tools.memory import save_user_preference

from langgraph.checkpoint.memory import MemorySaver
from langgraph.store.memory import InMemoryStore

# ì „ì—­ MCP í´ë¼ì´ì–¸íŠ¸
mcp_client = None

# HITL ë° Long-term Memoryë¥¼ ìœ„í•œ ì „ì—­ ì €ì¥ì†Œ
checkpointer = MemorySaver()
store = InMemoryStore()

class ResumeInput(BaseModel):
    thread_id: str
    decision: str  # approve, reject, edit
    edited_args: dict | None = None


# ============================================================================
# DeepAgent ì„¤ì • (ë¦¬í¬íŠ¸ ìƒì„± ì „ë¬¸ê°€)
# ============================================================================

# ëª¨ë¸ ì„¤ì • ë¡œë“œ
model_config = get_model_config()
model = init_chat_model(**model_config)

# System Prompt (WHO - ì •ì²´ì„±ê³¼ ì ˆëŒ€ ê·œì¹™)
system_prompt = get_system_prompt()

# AGENTS.md ê²½ë¡œ (WHEN + WHICH - ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™)
agents_md_path = get_agents_md_path()

# Skills ê²½ë¡œ (HOW - ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì¹¨)
skills_paths = get_skills_paths()

# Backend ì„¤ì • (FilesystemBackend)
agent_dir = Path(__file__).parent
backend = FilesystemBackend(root_dir=agent_dir)


async def process_report_request(input_data: ReportInput) -> dict:
    """ë¦¬í¬íŠ¸ ìƒì„± ìš”ì²­ ì²˜ë¦¬ (DeepAgent ì‚¬ìš©)"""
    
    global mcp_client

    # MCP ë„êµ¬ ê°€ì ¸ì˜¤ê¸° (ë¹„ë™ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    mcp_tools = await mcp_client.get_tools()
    
    # ë¡œì»¬ ë„êµ¬ì™€ MCP ë„êµ¬ ê²°í•©
    all_tools = [
        aggregate_by_standard_code,
        generate_markdown_report,
        get_exchange_rate,
        save_user_preference
    ] + mcp_tools
    
    # DeepAgent ìƒì„± (DeepAgents í‘œì¤€ íŒ¨í„´)
    agent = create_deep_agent(
        model=model,
        tools=all_tools,
        system_prompt=system_prompt,  # WHO
        memory=[agents_md_path],      # WHEN + WHICH (MemoryMiddlewareê°€ ë¡œë“œ)
        skills=skills_paths,           # HOW (SkillsMiddlewareê°€ ë¡œë“œ)
        backend=backend,
        checkpointer=checkpointer,     # Required for HITL
        interrupt_on={"get_exchange_rate": True}  # í™˜ìœ¨ ì¡°íšŒ ì‹œ ì¸í„°ëŸ½íŠ¸
    )
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
    user_message = f"""ë‹¤ìŒ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

ì™¸ë¶€ ì½”ë“œ ëª©ë¡: {input_data.external_codes}
ìˆ˜ëŸ‰ ëª©ë¡: {input_data.quantities}
"""

    if input_data.instruction:
        user_message += f"\nì¶”ê°€ ì§€ì¹¨: {input_data.instruction}\n"

    user_message += """
1. ë¨¼ì € batch_convert_codes ë„êµ¬ë¡œ ì™¸ë¶€ ì½”ë“œë¥¼ ë³€í™˜í•˜ì„¸ìš”.
2. ê·¸ ë‹¤ìŒ aggregate_by_standard_codeë¡œ ìˆ˜ëŸ‰ì„ ì§‘ê³„í•˜ì„¸ìš”.
3. ë§ˆì§€ë§‰ìœ¼ë¡œ generate_markdown_reportë¡œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”."""
    
    # DeepAgent ì‹¤í–‰ (thread_id í¬í•¨)
    import uuid
    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    print(f"ğŸ”„ ë¦¬í¬íŠ¸ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘ (Thread ID: {thread_id})")
    
    print("ğŸ¤– ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘...")
    try:
        # ë¹„ë™ê¸° ì‹¤í–‰ (ainvoke ì‚¬ìš©)
        result = await agent.ainvoke(
            {
                "messages": [
                    {"role": "user", "content": user_message}
                ]
            },
            config=config
        )
    except Exception as e:
        print(f"âŒ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise e
        
    print("âœ… ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ")
    
    # ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬
    if result.get("__interrupt__"):
        print("â¸ï¸ ì¸í„°ëŸ½íŠ¸ ê°ì§€ë¨")
        return {
            "status": "interrupted",
            "thread_id": thread_id,
            "interrupts": result["__interrupt__"][0].value,
            "messages": [m.content for m in result["messages"]]
        }
    
    print("ğŸ‰ ìµœì¢… ê²°ê³¼ ë°˜í™˜")
    # ê²°ê³¼ì—ì„œ ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
    final_message = result["messages"][-1].content
    
    return {
        "status": "completed",
        "thread_id": thread_id,
        "report": final_message,
        "summary": {
            "input_codes": input_data.external_codes,
            "input_quantities": input_data.quantities,
            "total_items": len(input_data.external_codes),
        }
    }


# ============================================================================
# FastAPI ì•± ì„¤ì •
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    print("ğŸš€ Report Generator Agent Server (DeepAgents) ì‹œì‘...")
    print(" AGENTS.md: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ë¡œë“œë¨")
    print("ğŸ¯ Skills: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì¹¨ ë¡œë“œë¨")
    
    global mcp_client
    mcp_server_config = get_mcp_server_config()
    print(f"ğŸ“‹ MCP ì„œë²„ ì„¤ì •: {list(mcp_server_config.keys())}")
    
    mcp_client = MultiServerMCPClient(mcp_server_config)

    yield
    
    print("ğŸ‘‹ ì„œë²„ ì¢…ë£Œ")
    # MCP Client Cleanup
    if mcp_client:
        try:
            await mcp_client.__aexit__(None, None, None)
        except Exception:
            pass


app = FastAPI(
    title="Report Generator Agent (DeepAgents)",
    description="DeepAgents í”„ë ˆì„ì›Œí¬ ê¸°ë°˜: ì™¸ë¶€ ì½”ë“œë¥¼ í‘œì¤€ ì½”ë“œë¡œ ë³€í™˜í•˜ê³  ì§‘ê³„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±",
    version="3.2.0",
    lifespan=lifespan,
)

# UI ì •ì  íŒŒì¼ ì œê³µ
static_dir = Path(__file__).parent / "static"
static_dir.mkdir(exist_ok=True)
app.mount("/ui", StaticFiles(directory=str(static_dir), html=True), name="ui")

@app.post("/report/resume")
async def resume_report(input_data: ResumeInput):
    """ì¤‘ë‹¨ëœ ë¦¬í¬íŠ¸ ìƒì„± ì¬ê°œ"""
    global mcp_client
    
    # ë„êµ¬ ë° ì—ì´ì „íŠ¸ ì¬êµ¬ì„± (ë™ì¼í•œ ì„¤ì • í•„ìš”)
    mcp_tools = await mcp_client.get_tools()
    all_tools = [
        aggregate_by_standard_code,
        generate_markdown_report,
        get_exchange_rate,
        save_user_preference
    ] + mcp_tools
    
    # ì¸í„°ëŸ½íŠ¸ ì„¤ì •
    interrupt_on = {"get_exchange_rate": True}
    
    # ìˆ˜ì •(edit) ê²°ì •ì¸ ê²½ìš°, í•´ë‹¹ ë„êµ¬ì˜ ì¸í„°ëŸ½íŠ¸ë¥¼ ë¹„í™œì„±í™”í•˜ì—¬ ë¬´í•œ ë£¨í”„ ë°©ì§€
    if input_data.decision == "edit":
        # í˜„ì¬ ì½”ë“œì—ì„œëŠ” get_exchange_rateë§Œ ì¸í„°ëŸ½íŠ¸ ëŒ€ìƒì´ë¯€ë¡œ ì´ë¥¼ ìˆ˜ì • ì¤‘ì´ë¼ë©´ ì œì™¸
        if "get_exchange_rate" in interrupt_on:
             del interrupt_on["get_exchange_rate"]

    agent = create_deep_agent(
        model=model,
        tools=all_tools,
        system_prompt=system_prompt,
        memory=[agents_md_path],
        skills=skills_paths,
        backend=backend,
        checkpointer=checkpointer,
        interrupt_on=interrupt_on
    )
    
    config = {"configurable": {"thread_id": input_data.thread_id}}
    
    # ê²°ì • êµ¬ì„±
    decisions = []
    if input_data.decision == "approve":
        decisions = [{"type": "approve"}]  # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ì‹¤í–‰
    elif input_data.decision == "reject":
        decisions = [{"type": "reject"}]  # ë„êµ¬ í˜¸ì¶œ ê±´ë„ˆë›°ê¸°
    elif input_data.decision == "edit":
        # íŒŒë¼ë¯¸í„° ìˆ˜ì • (ì˜ˆ: ë‹¤ë¥¸ í™”íë¡œ ë³€ê²½)
        decisions = [{
            "type": "edit",
            "edited_action": {
                "name": "get_exchange_rate",
                "args": input_data.edited_args
            }
        }]
    
    
    # ì¬ê°œ (ainvoke ì‚¬ìš©)
    try:
        result = await agent.ainvoke(
            Command(resume={"decisions": decisions}),
            config=config
        )
    except Exception as e:
        return {"error": str(e)}
    
    # ê²°ê³¼ ì²˜ë¦¬
    if result.get("__interrupt__"):
        return {
            "status": "interrupted",
            "thread_id": input_data.thread_id,
            "interrupts": result["__interrupt__"][0].value,
            "messages": [m.content for m in result["messages"]]
        }

    final_message = result["messages"][-1].content
    
    return {
        "status": "completed",
        "thread_id": input_data.thread_id,
        "report": final_message
    }


# ì²´ì¸ ë˜í¼ (LangServe í˜¸í™˜ - ë‹¨ìˆœí™”)
async def _process_input(input_data: dict) -> dict:
    """ì…ë ¥ ì²˜ë¦¬ ë˜í¼"""
    # LangServe ìš”ì²­ì€ ìƒˆë¡œìš´ thread_id ìƒì„± ë˜ëŠ” ì „ë‹¬ëœ ID ì‚¬ìš©
    if "instruction" not in input_data:
        input_data["instruction"] = None
        
    report_input = ReportInput(**input_data)
    
    # process_report_request modified to return dict
    result = await process_report_request(report_input)
    return result

# LangServe ë¼ìš°íŠ¸ ì¶”ê°€
add_routes(
    app,
    RunnableLambda(_process_input),
    path="/report",
)



@app.get("/")
async def root():
    """API ì •ë³´"""
    return {
        "name": "Report Generator Agent (DeepAgents)",
        "framework": "LangChain DeepAgents",
        "version": "3.0.0",
        "structure": {
            "system_prompt": "WHO - ì •ì²´ì„±ê³¼ ì ˆëŒ€ ê·œì¹™",
            "agents_md": "WHEN + WHICH - ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™",
            "skills": "HOW - ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì¹¨",
        },
        "endpoints": {
            "/report/invoke": "POST - ë¦¬í¬íŠ¸ ìƒì„±",
            "/report/stream": "POST - ìŠ¤íŠ¸ë¦¬ë° ë¦¬í¬íŠ¸ ìƒì„±",
            "/report/playground": "GET - ì¸í„°ë™í‹°ë¸Œ í”Œë ˆì´ê·¸ë¼ìš´ë“œ",
            "/docs": "GET - API ë¬¸ì„œ",
        }
    }


# ============================================================================
# ì„œë²„ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "agents.report_generator.server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
    )
